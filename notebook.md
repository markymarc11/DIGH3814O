
# Module 1

## Trevor Owens
- talks about how attaching links to articles that go back to the sources can make it easier to fact check
- he has a background in library archiving and working withing different aspects of digital history
- with such an easy way to fact check, it holds the historians to a higher standard
## Caleb McDaniel
- talks about having an open notebook from the very beginning of a project, not just posting your information at the end or post-humously
- open notebook science
- benefit of having ti all open
- you get another set of eyes which could help bring light to something that you may not have seen before
-  diadvantages of eveeryhing being open
- you are under scrutiny the whole time you are doing your work, and if you get a lot of negative feedback it could deter your from doing your work. 
- version control can be important, so you know what you did and when you did it
- HE doesn't tend to talk about himself that much on his website, more just what he has done
## Ian Milligan
- Talking about SSHRC grants and uploading information in a timely manner
- believes in sharing data betwween people, and that all the information should be made assessible, making everyones life easier
## Michelle Moravec 
- writes everything in a public domain so that she can have critique and comments throughout the process. 

# Module 2

## Big Data
- Big data is basically the idea of talking about larger amounts of data that need to be processed with through the use of technology, because it would not be humanly possible to go through and analyze it all within a certain time frame
- there has been a logging of all the data in the internet since 1996 with it amassing over 10 petabytes of data in 2012
- what are we doing with all of this data though, and will it be helpful for us to use, it it accessible
-  looking at the idea of how even though all of this data is out there, it may not be accessible
- an example of this is all of the data available on databases that are becoming inncreasingly more expensive for universities to access
-  this means that the data may not be made available to everyone
- General Purpose Computing, basically talking about how computers are part of everything that we do
- looking at how this interaction will be going forward, what kind of rules or regulations we will need to put around it
- how can we work with technology as well
- property law, if it's mine I should be able to do whatever I want with it!
- If everyone is trying to do their own thing making their own codes for things like self-driving cars, we will still need to find a way to 

# Module 3

## Data is Messy
- Dr. Grahams article talks about ways in which data can be crowd sourced, in areas that may not have very good technological hook ups
- The problems that came along with this though, people not being sure what they were doing
- you can also crowd source information by going through previously made information that has been put online
- 

# Module 4
## Corpus linguistics for Historians
- using computers to analya texts
- computers have a better chance of noticing patterns than humans may
- are able to analyze even the small words which we tend to look over
- looking at the ways in which you can analyze large works to find correlations and patterns
- when looking at gender rolls, and who is writing about them, it is interesting to see the wording that males and females use
## Everything on paper will be used against me
- looking at how certain words when portrayed in a text plot appear closer to others, giving insight to what they are talkinga bout
- "vietnam" was closely connected to "bombing" representing what they were probably doing in vietnam at the time
- examples like this can give us a starting point of where to go, without having to read everything
